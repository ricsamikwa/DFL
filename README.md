# Dynamic Federated Split Learning
### Efficient distributed training of deep neural networks in data and resource heterogeneous dynamic edge learning environments. 
DFL enhances training efficiency in heterogeneous dynamic IoT through resource-aware split computing of deep neural networks and dynamic clustering of training participants based on the similarity of their sub-model layers. Through resource-aware split learning, the allocation of the training tasks to resource-constrained participants is adjusted to align with the varied computational capabilities and the dynamic nature of communication resources of the participant devices. To navigate the complexities of training data heterogeneity without compromising data privacy or necessitating the transmission of raw data over networks, DFL utilizes the layerwise similarity of neural network representations.

## Refactoring in progress ==>

## Full instructions TBA ...

Run test DFL unit in `DFL_training` folder:
```
python3 run_DFL_unit.py --group True
```